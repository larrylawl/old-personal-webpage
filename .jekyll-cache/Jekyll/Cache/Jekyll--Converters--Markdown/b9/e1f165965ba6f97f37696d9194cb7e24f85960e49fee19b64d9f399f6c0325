I"7<h2 id="learning-outcomes">Learning outcomes</h2>
<ol>
  <li>Understand Underfitting and Overfitting</li>
  <li>Understand the intuition for Regularisation</li>
  <li>Implementing Regularisation and understand the tradeoff between Underfitting and Overfitting</li>
</ol>

<h2 id="understanding-underfitting-and-overfitting">Understanding Underfitting and Overfitting</h2>
<p><img src="/assets/img/fitting.jpg" alt="fitting" /></p>

<p>Underfitting (left) is when the hypothesis function maps poorly to the trend of the data. Notice how the $ h_\theta{x} $ is a linear function while the data is quadratic.</p>

<!-- TODO: Regularise can still screw up for new data -->
<h2 id="intuition-for-regularisation">Intuition for Regularisation</h2>

<h2 id="implementation-for-regularisation">Implementation for Regularisation</h2>

<h2 id="the-tradeoff-between-underfitting-and-overfitting">The Tradeoff between Underfitting and Overfitting</h2>

<h2 id="credits">Credits</h2>

<h2 id="prerequisites-gradient-descent">Prerequisites: Gradient Descent</h2>
<p>Read more about gradient descent in my post <a href="./gradient-descent.html">here</a>.</p>

<h2 id="purpose-of-vectorisation">Purpose of Vectorisation</h2>
<p><img src="/assets/img/vectorisation.jpg" alt="vectorisation" /></p>

<p>Notice how the vectorised form is…</p>

<ol>
  <li>Easier to implement (thus having less bugs)</li>
  <li>More efficient (since we are calling the optimised linear algebra library)</li>
</ol>

<h2 id="from-partial-derivatives-to-summation">From partial derivatives to summation…</h2>
<p>Recall that gradient descent is defined as such:</p>

<script type="math/tex; mode=display">\theta_{j}:=\theta_{j}-\alpha \frac{\partial}{\partial \theta_{j}} J\left(\theta_{0}, \theta_{1}, ..., \theta_{n}\right)</script>

<p>It turns out that the partial derivative term can be simplified as followed:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned} \frac{\partial}{\partial \theta_{j}} J(\theta) &=\frac{\partial}{\partial \theta_{j}} \frac{1}{2}\left(h_{\theta}(x)-y\right)^{2} \\ &=2 \cdot \frac{1}{2}\left(h_{\theta}(x)-y\right) \cdot \frac{\partial}{\partial \theta_{j}}\left(h_{\theta}(x)-y\right) \\ &=\left(h_{\theta}(x)-y\right) \cdot \frac{\partial}{\partial \theta_{j}}\left(\sum_{i=0}^{n} \theta_{i} x_{i}-y\right) \\ &=\left(h_{\theta}(x)-y\right) x_{j} \end{aligned} %]]></script>

<p>Thus our simultaneous update can be written as:</p>

<p><script type="math/tex">\begin{array}{l}{\text { repeat until convergence: }\{} \\ {\qquad \begin{array}{l}{\theta_{0}:=\theta_{0}-\alpha \frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x_{i}\right)-y_{i}\right)} \\ {\theta_{1}:=\theta_{1}-\alpha \frac{1}{m} \sum_{i=1}^{m}\left(\left(h_{\theta}\left(x_{i}\right)-y_{i}\right) x_{i}^1\right)} \\ ... \\
\theta_{n}:=\theta_{n}-\alpha \frac{1}{m} \sum_{i=1}^{m}\left(\left(h_{\theta}\left(x_{i}\right)-y_{i}\right) x_{i}^n\right) \\
\}
\end{array}}\end{array}</script></p>
<blockquote>
  <p>Remeber to use simultaneous update!</p>
</blockquote>

<h2 id="from-summation-to-vector">From summation to vector…</h2>
<p>Claim that $ \theta $ can be rewritten from summation form (as above) to vector form (as below):</p>

<script type="math/tex; mode=display">\theta:=\theta-\alpha \delta, where\\
\delta := \frac{1}{m} X^{T}(X \theta-\vec{y})</script>

<p>Let H denote the hypothesis matrix,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{array}{l}{\dot{H}_{m \times 1}:=\left(\begin{array}{c}{h_{\theta}\left(x^{1}\right)} \\ {h_{\theta}\left(x^{2}\right)} \\ {\vdots} \\ {h_{\theta}\left(x^{m}\right)}\end{array}\right)=X \theta} & 

\end{array} %]]></script>

<p>Let E denote the error matrix,</p>

<script type="math/tex; mode=display">E_{m \times 1}:=\left(\begin{array}{c}{e_{1}} \\ {e_{2}} \\ {\vdots} \\ {e_{m}}\end{array}\right)=\left(\begin{array}{c}{h_{\theta}\left(x^{1}\right)-y^{1}} \\ {h_{\theta}\left(x^{2}\right)-y^{2}} \\ 
{\vdots} \\
{h_{\theta}\left(x^{m}\right)-y^{m}}\end{array}\right)_{m \times 1}=H-\vec{y}</script>

<p>Let $ \delta $ denote the summation term</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned} \delta_{j} &:=\frac{1}{n} \sum_{i=1}^{n}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)} \\ &=\frac{1}{m}\left(e_{1} x_{j}^{1}+e_{2} x_{j}^{2}+\ldots+e_{m} x_{j}^{m}\right) \\ &=\frac{1}{m} x_{j}^{\top} E \\ \end{aligned} %]]></script>

<script type="math/tex; mode=display">\begin{array}{c}{\delta:=\left(\begin{array}{c}{\delta_{0}} \\ {\delta_{1}} \\ {\vdots} \\ {\delta_{n}}\end{array}\right)=\frac{1}{m} X^{\top} E}\end{array}</script>

<script type="math/tex; mode=display">{\theta=\theta-\alpha \delta} = {\theta-\frac{\alpha}{m} X^{T}(X \theta-\vec{y})} \text{ (shown)}\\</script>

<blockquote>
  <p>Note that this vectorised form applies for <strong>logistic regression too.</strong> Recall that logistic regression has the same gradient descent formula, with the only difference being that the hypothesis function of a logistic regression is a function of the linear regression (ie $ h_{\theta}(x) = g(\theta^Tx) $).</p>

  <p>Thus for logistic regression, we will need to substitute the hypothesis matrix to be a function of the linear regression.</p>
</blockquote>

<script type="math/tex; mode=display">H = g(X\theta)</script>

<blockquote>
  <p>Vectorised formula will be as follow:</p>
</blockquote>

<script type="math/tex; mode=display">{\theta=\theta-\alpha \delta} = {\theta-\frac{\alpha}{m} X^{T}(g(X \theta)-\vec{y})}\\</script>

<h2 id="credits-1">Credits</h2>
<p>Andrew Ng’s Machine Learning course. Source <a href="https://www.coursera.org/learn/machine-learning">here</a></p>
:ET