I"„u<!-- omit in toc -->
<h1 id="machine-learning-coursera-notes">Machine Learning Coursera Notes</h1>

<p>Lecturer: Professor Andrew Ng <br />
Source: <a href="https://www.coursera.org/learn/machine-learning/home/welcome">here</a></p>

<blockquote>
  <p>All code is written in MatLab/Octave.</p>
</blockquote>

<!-- omit in toc -->
<h2 id="table-of-contents">Table of Contents</h2>
<ul>
  <li><a href="#week-1">Week 1</a>
    <ul>
      <li><a href="#learning-outcomes">Learning Outcomes</a></li>
      <li><a href="#machine-learning">Machine learning</a></li>
      <li><a href="#cost-function">Cost Function</a></li>
      <li><a href="#gradient-descent">Gradient Descent</a></li>
    </ul>
  </li>
  <li><a href="#week-2-multivariate-linear-regression">Week 2: Multivariate Linear Regression</a>
    <ul>
      <li><a href="#learning-outcomes">Learning outcomes</a></li>
      <li><a href="#denoting-multiple-features">Denoting multiple features</a></li>
      <li><a href="#linear-regression-with-multiple-variables">Linear regression with multiple variables</a></li>
      <li><a href="#gradient-descent-for-multiple-variables">Gradient Descent for multiple variables</a></li>
      <li><a href="#feature-scaling">Feature Scaling</a></li>
      <li><a href="#how-to-adjust-learning-rate">How to adjust learning rate?</a></li>
      <li><a href="#what-is-feature-combination">What is feature combination?</a></li>
      <li><a href="#what-is-polynomial-regression">What is polynomial regression?</a></li>
    </ul>
  </li>
  <li><a href="#week-2-computing-parameters-analytically">Week 2: Computing Parameters Analytically</a>
    <ul>
      <li><a href="#learning-outcomes-1">Learning Outcomes</a></li>
      <li><a href="#why-do-we-need-normal-equation">Why do we need normal equation?</a></li>
      <li><a href="#the-math-behind-normal-equation">The math behind normal equation</a></li>
      <li><a href="#normal-equation-vs-gradient-descent">Normal Equation vs Gradient Descent</a></li>
      <li><a href="#causes-for-normal-equation-noninvertibility">Causes for Normal Equation noninvertibility</a></li>
    </ul>
  </li>
  <li><a href="#week-3-classification-and-representation">Week 3: Classification and Representation</a>
    <ul>
      <li><a href="#learning-outcomes-2">Learning Outcomes</a></li>
      <li><a href="#sigmoidlogistic-function-why-and-what">Sigmoid/Logistic Function: why and what?</a></li>
      <li><a href="#decision-boundary-what">Decision boundary: what</a></li>
      <li><a href="#decision-boundary-how-to-compute">Decision boundary: how to compute</a></li>
    </ul>
  </li>
  <li><a href="#week-3-logistic-regression-model">Week 3: Logistic Regression Model</a>
    <ul>
      <li><a href="#learning-outcomes-3">Learning Outcomes</a></li>
      <li><a href="#what-is-the-cost-function-of-the-logistic-regression-model">What is the Cost Function of the Logistic Regression Model</a></li>
      <li><a href="#gradient-descent-of-the-updated-cost-function">Gradient Descent of the updated Cost Function</a></li>
      <li><a href="#advanced-optimisation-why-and-what">Advanced Optimisation: why and what</a></li>
      <li><a href="#advanced-optimisation-how">Advanced Optimisation: how</a></li>
    </ul>
  </li>
  <li><a href="#week-3-multiclass-classification">Week 3: Multiclass Classification</a>
    <ul>
      <li><a href="#learning-outcomes-4">Learning Outcomes</a></li>
      <li><a href="#what-is-multiclass-classification-how-do-we-implement-it">What is multiclass classification? How do we implement it?</a></li>
    </ul>
  </li>
  <li><a href="#week-3-solving-the-problem-of-overfitting">Week 3: Solving the Problem of Overfitting</a>
    <ul>
      <li><a href="#learning-outcomes-5">Learning Outcomes</a></li>
      <li><a href="#understanding-underfitting-and-overfitting">Understanding Underfitting and Overfitting</a></li>
      <li><a href="#implementation-for-regularisation">Implementation for Regularisation</a></li>
      <li><a href="#the-tradeoff-between-underfitting-and-overfitting">The Tradeoff between Underfitting and Overfitting</a></li>
      <li><a href="#regularised-linear-regression">Regularised Linear Regression</a></li>
      <li><a href="#regularised-logistic-regression">Regularised Logistic Regression</a></li>
    </ul>
  </li>
  <li><a href="#credits">Credits</a></li>
</ul>

<h2 id="week-1">Week 1</h2>
<h3 id="learning-outcomes">Learning Outcomes</h3>
<ol>
  <li>What is (1) machine learning, (2) supervised learning and types of (2), (3) unsupervised learning and types of (3)</li>
  <li>What is the cost function?</li>
  <li>What is gradient descent?</li>
</ol>

<h3 id="machine-learning">Machine learning</h3>
<p>The field of study that gives computers the ability to learn without being explicitly programmed.</p>
<ol>
  <li>
    <p><strong>Supervised Learning</strong>: ‚ÄúKnow the right answers.</p>

    <ul>
      <li><strong>Regression</strong>: Predict results within a <em>continuous output</em></li>
      <li><strong>Classification</strong>: Map input variables to a <em>discrete output</em></li>
    </ul>
  </li>
  <li>
    <p><strong>Unsupervised Learning</strong>: No idea what our results should look like</p>
    <ul>
      <li><strong>Clustering</strong></li>
    </ul>
  </li>
</ol>

<h3 id="cost-function">Cost Function</h3>
<!-- TODO: Add in convex vs non-convex cost function, cost functions of diff type of machine learning algo (MSE for linear regression, x for logistic etc) -->
<p>Refer to post on gradient descent <a href="./gradient-descent.html">here</a>. The below is the 0.5 * Mean-Squared-Error (MSE) cost function.</p>

<script type="math/tex; mode=display">J\left(\theta_{0}, \theta_{1}\right)=\frac{1}{2 m} \sum_{i=1}^{m}\left(\hat{y}_{i}-y_{i}\right)^{2}=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x_{i}\right)-y_{i}\right)^{2}</script>

<p>Vectorised form:</p>

<script type="math/tex; mode=display">\begin{array}{l}{\qquad J(\theta)=\frac{1}{2 m}(X \theta-\vec{y})^{T}(X \theta-\vec{y})} \\ {\text { where }} \\ {\qquad X=\left[\begin{array}{c}{-\left(x^{(1)}\right)^{T}-} \\ {-\left(x^{(2)}\right)^{T}-} \\ {\vdots} \\ {-\left(x^{(m)}\right)^{T}-}\end{array}\right] \quad \vec{y}=\left[\begin{array}{c}{y^{(1)}} \\ {\vdots} \\ {y^{(m)}}\end{array}\right]}\end{array}</script>

<blockquote>
  <p>Note: cost function is a function of the model parameters $ h_\theta $ while hypothesis function is a function of the variables $ x $‚Ä¶</p>
</blockquote>

<h3 id="gradient-descent">Gradient Descent</h3>
<p>Refer to post on gradient descent <a href="./gradient-descent.html">here</a>.</p>

<h2 id="week-2-multivariate-linear-regression">Week 2: Multivariate Linear Regression</h2>
<h3 id="learning-outcomes-1">Learning outcomes</h3>
<ol>
  <li>What is multivariate linear regression?</li>
  <li>Gradient descent for multiple variables?</li>
  <li>Feature scaling: why and how?</li>
  <li>How to adjust the learning rate?</li>
  <li>What is feature combination?</li>
  <li>What is polynomial regression?</li>
</ol>

<h3 id="denoting-multiple-features">Denoting multiple features</h3>

<script type="math/tex; mode=display">x^{i}_j \text{= value of feature j in the ith training example} \\

x^{i} \text{= input features of the ith training example}</script>

<h3 id="linear-regression-with-multiple-variables">Linear regression with multiple variables</h3>

<p>Vectorised form:</p>

<script type="math/tex; mode=display">% <![CDATA[
h_{\theta}(x)=\left[\begin{array}{llll}{\theta_{0}} & {\theta_{1}} & {\ldots} & {\theta_{n}}\end{array}\right]\left[\begin{array}{c}{x_{0}} \\ {x_{1}} \\ {\vdots} \\ {x_{n}}\end{array}\right]=\theta^{T} x %]]></script>

<h3 id="gradient-descent-for-multiple-variables">Gradient Descent for multiple variables</h3>
<blockquote>
  <p>Similar to gradient descent for single variable.
<script type="math/tex">\begin{array}{l}{\text { repeat until convergence: }\{} \\ {\theta_{j}:=\theta_{j}-\alpha \frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) \cdot x_{j}^{(i)} \quad \text { for } j:=0 \ldots n} \\ {\}}\end{array}</script></p>
</blockquote>

<p>Vectorised form of Gradient Descent for linear regression (derivation <a href="./gradient-descent-linear-regression.html">here</a>):</p>

<script type="math/tex; mode=display">\theta:=\theta-\frac{\alpha}{m} X^{T}(X \theta-\vec{y})</script>

<h3 id="feature-scaling">Feature Scaling</h3>
<p>Refer to post on feature scaling <a href="./feature-scaling.html">here</a></p>

<h3 id="how-to-adjust-learning-rate">How to adjust learning rate?</h3>
<ol>
  <li><strong>Debugging gradient descent</strong>: Plotting a graph of the cost function over no. of iterations. If the cost function ever increases, the learning rate is likely to be too high.
    <blockquote>
      <p>A high learning rate might cause divergence.</p>
    </blockquote>
  </li>
  <li><strong>Automatic convergence test</strong>: Declare convergence if the cost function decreases by less than E in one iteration, where E is some small value such as 10^-3.</li>
</ol>

<h3 id="what-is-feature-combination">What is feature combination?</h3>
<p>Eg $ x_3 = x_1 * x_2 $</p>

<h3 id="what-is-polynomial-regression">What is polynomial regression?</h3>
<p>Change the hypothesis function to a polynomial equation that better models the data (ie lower cost function).</p>

<script type="math/tex; mode=display">Square root: h_{\theta}(x)=\theta_{0}+\theta_{1} x_{1}+\theta_{2} \sqrt{x_{1}}</script>

<script type="math/tex; mode=display">Cubic: h_{\theta}(x)=\theta_{0}+\theta_{1} x_{1}+\theta_{2} x_{1}^{2}+\theta_{3} x_{1}^{3}</script>

<h2 id="week-2-computing-parameters-analytically">Week 2: Computing Parameters Analytically</h2>
<h3 id="learning-outcomes-2">Learning Outcomes</h3>
<ol>
  <li>Normal equation: why and what?</li>
  <li>Normal equation vs Gradient Descent</li>
  <li>Causes for normal equation non-invertability</li>
</ol>

<h3 id="why-do-we-need-normal-equation">Why do we need normal equation?</h3>
<p><strong>To obtain the optimum parameters <em>analytically</em>.</strong> In other words, the parameters are computed explicitly, instead of being estimated iteratively in gradient descent.</p>

<h3 id="the-math-behind-normal-equation">The math behind normal equation</h3>
<p>Recall that parameters are <em>optimum</em> when the cost function is minimum. Thus, we are interested in the value of the parameters at the minimum points of the cost function. <em>How do we obtain this value then?</em></p>

<p>In $ R_2 $, we do so by first setting the derivative of the function to be 0 (to obtain the points of inflexion), then solve for the value of the parameter at the minimum point.</p>

<p>Similarly in $ R_3 $, we first set the <em>partial derivative</em> with respect to $ \theta_0 $ to be 0, then we solve for $ \theta_0 $. Repeat iteratively till $ \theta_n $.</p>

<p>The result will arrive to the <strong>normal equation formula</strong>:</p>

<script type="math/tex; mode=display">\theta=\left(X^{T} X\right)^{-1} X^{T} y, where \\

X_{m\times(n+1)}=\left[\begin{array}{c}{1\left(x^{(1)}\right)^{\top}} \\ {1\left(x^{(n)}\right)^{\top}} \\ {\vdots} \\ {1\left(x^{(n)}\right)^{\top}}\end{array}\right]</script>

<blockquote>
  <p>There is <strong>no need</strong> to do feature scaling with normal equation as the purpose of feature scaling was to speed up gradient descent, which is a different method of obtaining the parameters.</p>
</blockquote>

<blockquote>
  <p>Note that $ (X^{\top}X) $ is non-invertible if m &lt; n. Proof as follows:</p>
</blockquote>

<ol>
  <li>rank(X) ‚â§ min(m, n+1)</li>
  <li>rank($ X^{\top}X $) = rank(X) (proof <a href="https://math.stackexchange.com/questions/349738/prove-operatornamerankata-operatornameranka-for-any-a-in-m-m-times-n">here</a>)</li>
  <li>Since m &lt; n, rank($ X^{\top}X $) ‚â§¬†m ‚â§ n + 1.</li>
  <li>rank($ X^{\top}X $) = n + 1 for it to be invertible.</li>
  <li>Hence $ X^{\top}X $ is non-invertible.</li>
</ol>

<h3 id="normal-equation-vs-gradient-descent">Normal Equation vs Gradient Descent</h3>

<p><img src="/assets/img/comparison.jpg" alt="Normal Equation vs Gradient Descent" /></p>

<!-- TODO: Normal equation only for linear regression? -->

<h3 id="causes-for-normal-equation-noninvertibility">Causes for Normal Equation noninvertibility</h3>
<p>If $ X^{T} X $ is <strong>noninvertible</strong>, the common causes include</p>
<ol>
  <li><strong>Redundant features:</strong> Features are closely related, thus they are linearly dependent (lie on the same span), hence the matrix containing these vectors results in a linear transformation that squishes input vectors to the single dimension (ie determinant is zero), thus its a noninvertible matrix.</li>
  <li><strong>Too many features</strong>. Delete some features or use regularisation</li>
</ol>

<h2 id="week-3-classification-and-representation">Week 3: Classification and Representation</h2>
<h3 id="learning-outcomes-3">Learning Outcomes</h3>
<ol>
  <li>Sigmoid/Logistic function: why and what?</li>
  <li>Decision boundary: why and how to compute?</li>
</ol>

<h3 id="sigmoidlogistic-function-why-and-what">Sigmoid/Logistic Function: why and what?</h3>
<p>We use the Logistic Function for <strong>classification problems</strong>. For now, let‚Äôs focus on <em>binary</em> classification problems (ie output is {0, 1}).</p>

<p>The hypothesis function of the logistic function <em>outputs</em> the <em>probability</em> that our output is 1 conditioned on our input data (ie $ x $), parameterised by our model‚Äôs parameter (ie $ ;\theta $).</p>

<p><script type="math/tex">h_\theta(x) = P(y = 1|x; \theta)</script></p>
<blockquote>
  <p><code class="highlighter-rouge">;</code> denote parameterised</p>
</blockquote>

<p>Since the logistic regression is used for the binary classification problem, we need to <em>translate</em> the output of the hypothesis function from (0, 1) to {0, 1}.</p>

<script type="math/tex; mode=display">% <![CDATA[
h_\theta(x) ‚â• 0.5 \rightarrow y = 1 \\
h_\theta(x) < 0.5 \rightarrow y = 0 %]]></script>

<p>Vectorised form of this translation</p>
<div class="language-m highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span> <span class="n">p</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="k">...</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mf">0.5</span> <span class="c1">% size = [m, 1]</span>
</code></pre></div></div>

<p>Internally, this hypothesis function is defined as such:</p>

<script type="math/tex; mode=display">h_\theta(x) = g(\theta^{\top}x) = g(z) = \frac{1}{1 + e^{-z}}</script>

<p>Vectorised form of the hypothesis function</p>
<div class="language-m highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span> <span class="n">g</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="k">...</span>
<span class="n">g</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">.</span><span class="p">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">.+</span> <span class="n">e</span> <span class="o">.^</span> <span class="o">-</span><span class="n">z</span><span class="p">)</span> <span class="c1">% size = [m, 1]</span>
</code></pre></div></div>

<p>Graphically, it looks like this:
<img src="/assets/img/logistic.jpg" alt="logistic function" />
Note certain properties of it</p>
<ol>
  <li><strong>$ h_\theta(x) \in (1, 0) $.</strong> This makes sense as the hypothesis function is a probability.</li>
  <li><strong>$ If x = 0, h_\theta(x) = 0.5 $.</strong> Intuitively, if the input data is null, the model will not have any information to make a prediction, thus the probability of the binary classification will be 0.5</li>
</ol>

<h3 id="decision-boundary-what">Decision boundary: what</h3>
<p>The decision boundary is the <strong>line</strong> that partitions y (ie. {0, 1}).</p>

<p><img src="/assets/img/decision-boundary-fit.jpg" alt="decision boundary" /></p>

<h3 id="decision-boundary-how-to-compute">Decision boundary: how to compute</h3>
<p>Let us start with an example.</p>

<p>We are interested in the inequality $ \theta^{\top}x ‚â• 0 $ as it partitions the output to {0, 1}. The heuristic explaining why it partitions is shown below:</p>

<script type="math/tex; mode=display">\theta^{\top}x ‚â• 0 \rightarrow g(\theta^{\top}x) ‚â• 0.5 \rightarrow y = 1</script>

<p>An example will clear things up.</p>

<script type="math/tex; mode=display">\begin{array}{l}{\theta=\left[\begin{array}{c}{5} \\ {-1} \\ {0}\end{array}\right]} \\ {y=1 \text { if } 5+(-1) x_{1}+0 x_{2} \geq 0} \\ {5-x_{1} \geq 0} \\ {-x_{1} \geq-5} \\ {x_{1} \leq 5}\end{array}</script>

<p>This inequality is useful as it tells us both the <em>equation of the decision boundary</em> (ie $ x_1 = 5 $) and the <em>how the training examples were partitioned</em> (ie $ x_1 ‚â§ 5 $ will be classified as 1).</p>

<blockquote>
  <p>Notice how the boundary line is not dependent on $ x_2 $</p>
</blockquote>

<h2 id="week-3-logistic-regression-model">Week 3: Logistic Regression Model</h2>
<h3 id="learning-outcomes-4">Learning Outcomes</h3>
<ol>
  <li>What is the Cost Function of the Logistic Regression Model? What is the Gradient Descent of it?</li>
  <li>Advanced optimisation: why, what and how?</li>
</ol>

<h3 id="what-is-the-cost-function-of-the-logistic-regression-model">What is the Cost Function of the Logistic Regression Model</h3>

<script type="math/tex; mode=display">J(\theta)=-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)} \log \left(h_{\theta}\left(x^{(i)}\right)\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]</script>

<p>Vectorised form</p>

<div class="language-m highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">g</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span><span class="p">);</span>
<span class="n">J</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="p">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">y</span><span class="s1">' * log(g) - (1 - y'</span><span class="p">)</span> <span class="o">*</span> <span class="nb">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">g</span><span class="p">));</span>
</code></pre></div></div>

<p>Plotting the graph of the Cost Function,
<img src="/assets/img/cost-function-graph.jpg" alt="cost function graph" />
Note the following properties</p>
<ol>
  <li>If y = 1 and the model predicts y = 0 (ie $ h_\theta(x) \rightarrow 0 $), the cost tends to infinity. Likewise for the opposite case (if y = 0 and the model predicts y = 1).</li>
  <li>$ {\operatorname{cost}\left(h_{\theta}(x), y\right)=0 \text { if } h_{\theta}(x)=y} $</li>
</ol>

<h3 id="gradient-descent-of-the-updated-cost-function">Gradient Descent of the updated Cost Function</h3>
<p>Exactly the same as linear regression (can be shown through calculus).</p>

<script type="math/tex; mode=display">{\theta=\theta-\alpha \delta} = {\theta-\frac{\alpha}{m} X^{T}(g(X \theta)-\vec{y})}\\</script>

<h3 id="advanced-optimisation-why-and-what">Advanced Optimisation: why and what</h3>
<p>They <strong>learn the model‚Äôs parameters more quickly wo learning rate</strong>. Examples include ‚ÄúConjugate gradient‚Äù, ‚ÄúBFGS‚Äù, and ‚ÄúL-BFGS‚Äù.</p>

<h3 id="advanced-optimisation-how">Advanced Optimisation: how</h3>
<div class="language-m highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span> <span class="p">[</span><span class="n">J</span><span class="p">,</span> <span class="n">grad</span><span class="p">]</span> <span class="o">=</span> <span class="n">costFunction</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span><span class="p">);</span>
<span class="k">...</span>
<span class="n">J</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="p">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">y</span><span class="s1">' * log(g) - (1 - y'</span><span class="p">)</span> <span class="o">*</span> <span class="nb">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">g</span><span class="p">));</span>
<span class="n">grad</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="p">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="o">'</span> <span class="o">*</span> <span class="p">(</span><span class="n">g</span> <span class="o">-</span> <span class="n">y</span><span class="p">);</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="week-3-multiclass-classification">Week 3: Multiclass Classification</h2>
<h3 id="learning-outcomes-5">Learning Outcomes</h3>
<ol>
  <li>What is multiclass classification? How do we implement it?</li>
</ol>

<h3 id="what-is-multiclass-classification-how-do-we-implement-it">What is multiclass classification? How do we implement it?</h3>
<p>Classifying data in &gt; 2 categories (ie y = {0, 1, ‚Ä¶ , n}). We do so by adopting the <strong>one-vs-all</strong> algorithm.
<script type="math/tex">% <![CDATA[
\begin{aligned} y & \in\{0,1 \ldots n\} \\ h_{\theta}^{(0)}(x) &=P(y=0 | x ; \theta) \\ h_{\theta}^{(1)}(x) &=P(y=1 | x ; \theta) \\ \cdots & \\ h_{\theta}^{(n)}(x) &=P(y=n | x ; \theta) \\ \text { prediction } &=\max \left(h_{\theta}^{(i)}(x)\right) \\ & \end{aligned} %]]></script></p>

<p><img src="/assets/img/multiclass.jpg" alt="multiclass" /></p>

<h2 id="week-3-solving-the-problem-of-overfitting">Week 3: Solving the Problem of Overfitting</h2>
<h3 id="learning-outcomes-6">Learning Outcomes</h3>
<ol>
  <li>Understanding Underfitting and Overfitting</li>
  <li>Implementing Regularisation and understand the tradeoff between Underfitting and Overfitting</li>
  <li>Regularized linear regression</li>
  <li>Regularized logistic regression</li>
</ol>

<h3 id="understanding-underfitting-and-overfitting">Understanding Underfitting and Overfitting</h3>
<p><img src="/assets/img/fitting.jpg" alt="fitting" /></p>

<p>Underfitting (left) is when the hypothesis function, $ h_\theta{x} $, maps poorly to the trend of the data._ Notice how the $ h_\theta{x} $ is a linear function while the data is quadratic (mid). Underfitting is usually caused by a function that is too simple.</p>

<p>Overfitting (right) is when the $ h_\theta{x} $ fits the available data but does not generalise well to predict new data. Notice how $ h_\theta{x} $ fits the test data well, but does not have any structure that shows that it can predict new data equally well.</p>

<p>To address overfitting, we can either (1) Reduce number of features or (2) implement <strong>regularisation</strong>.</p>

<h3 id="implementation-for-regularisation">Implementation for Regularisation</h3>
<p><script type="math/tex">J(\theta)= E(\theta) + \frac{\lambda}{2 m} \sum_{j=1}^{n} \theta_{j}^{2}, where \\
E(\theta) = \text{error function}</script></p>
<blockquote>
  <p>Regularisation term starts from j = 1, not 0. We don‚Äôt penalise $ tetha_0 $ as the term was introduced for neater notation.
We regulate all parameters as we are not able to predict which parameter is more important than the other.</p>
  <h3 id="the-tradeoff-between-underfitting-and-overfitting">The Tradeoff between Underfitting and Overfitting</h3>
  <!-- Regularisation doesn't mean it will predict well for next training data -->
  <p>Recall that the error function (1st term) measures how different our model‚Äôs prediction is from the expected value. Optimising the error function allows us to fit the training sample better at the risk of overfitting.</p>
</blockquote>

<p>Regularisation (2nd term), on the other hand, reduces the magnitude of the parameters, thus smoothing out the hypothesis function, and <em>reduce overfitting</em> at the risk of <em>underfitting</em>.</p>
<blockquote>
  <p>While it reduces overfitting, implementing regularisation does not always mean the model will predict well for new training samples; too much regularisation will cause underfitting, which will lead to poorer prediction.</p>
</blockquote>

<p>Thus the new cost function is the summation of both the error function and regularisation, as a better attempt to optimise the tradeoff between underfitting and overfitting.</p>

<h3 id="regularised-linear-regression">Regularised Linear Regression</h3>
<p>Gradient Descent:
<script type="math/tex">\begin{array}{l}{\text { Repeat }\{} \\ {\qquad \begin{array}{l}{\theta_{0}:=\theta_{0}-\alpha \frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{0}^{(i)}} \\ {\theta_{j}:=\theta_{j}-\alpha\left[\left(\frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}\right)+\frac{\lambda}{m} \theta_{j}\right]}\\ \}\end{array}} \\ \end{array}</script></p>

<p>Rearranging‚Ä¶
<script type="math/tex">\theta_{j}:=\theta_{j}\left(1-\alpha \frac{\lambda}{m}\right)-\alpha \frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}</script></p>

<blockquote>
  <p>Note that $ (1-\alpha \frac{\lambda}{m} $ &lt; 1. Intuitively you can see it as reducing the value of $ \theta_j $ by some amount on every update, which is the purpose of regularisation.</p>
</blockquote>

<p>Normal Equation</p>

<p><script type="math/tex">% <![CDATA[
\begin{array}{l}{\theta=\left(X^{T} X+\lambda \cdot L\right)^{-1} X^{T} y} \\ {\text { where } L=\left[\begin{array}{cccc}{0} \\ {} & {1} \\ {} & {} & {1} \\ {} & {} & {} & {1}\end{array}\right]}\end{array} %]]></script></p>
<blockquote>
  <p>Adding the term Œª‚ãÖL, then $ (X^{T} X+\lambda \cdot L\right) $ becomes invertible.</p>
</blockquote>

<h3 id="regularised-logistic-regression">Regularised Logistic Regression</h3>
<p><script type="math/tex">J(\theta)=-\frac{1}{m} \sum_{i=1}^{m}\left[y^{(i)} \log \left(h_{\theta}\left(x^{(i)}\right)\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]+\frac{\lambda}{2 m} \sum_{j=1}^{n} \theta_{j}^{2}</script></p>

<div class="language-m highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span> <span class="p">[</span><span class="n">J</span><span class="p">,</span> <span class="n">grad</span><span class="p">]</span> <span class="o">=</span> <span class="n">costFunctionReg</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda</span><span class="p">)</span>
<span class="k">...</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">theta</span><span class="p">);</span>
<span class="n">e</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="p">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">y</span><span class="s1">' * log(g) - (1 - y'</span><span class="p">)</span> <span class="o">*</span> <span class="nb">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">g</span><span class="p">));</span> <span class="c1">% error term</span>
<span class="n">newTheta</span> <span class="o">=</span> <span class="n">theta</span><span class="p">;</span>
<span class="n">newTheta</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="n">r</span> <span class="o">=</span> <span class="p">(</span><span class="n">lambda</span> <span class="p">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">newTheta</span><span class="o">'</span> <span class="o">*</span> <span class="n">newTheta</span><span class="p">);</span>
<span class="n">J</span> <span class="o">=</span> <span class="n">e</span> <span class="o">+</span> <span class="n">r</span><span class="p">;</span>
<span class="n">grad</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="p">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="o">'</span> <span class="o">*</span> <span class="p">(</span><span class="n">g</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">lambda</span> <span class="p">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">newTheta</span><span class="p">;</span>
</code></pre></div></div>

<h2 id="credits">Credits</h2>
<p>Andrew Ng‚Äôs Machine Learning course. Source <a href="https://www.coursera.org/learn/machine-learning">here</a></p>
:ET