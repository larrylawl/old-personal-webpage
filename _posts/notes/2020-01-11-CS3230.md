---
layout: post
title: "NUS, CS3230: Design and Analysis of Algorithms"
author: "Larry Law"
categories: notes
image: cs.jpeg
hidden: true
---
Lecturer: [Professor Sung Wing Kin, Ken](https://www.comp.nus.edu.sg/cs/bio/ksung/) <br>

TODO:
1. Qn 4 of lecture

<!-- omit in toc -->
# Table of Contents

# Overview
## Course Objectives
1. Learns tools to analyse the performance of algorithms
2. Learns techniques to design an efficient algorithm.

# Correctness
## Reasoning and Asymptotic Analysis
### What is a good algorithm?
1. Correct
2. Efficient
3. Well-documented and with sufficient details
4. Maintainable

## Correctness of Iterative Algorithm

**Loop Invariant**
1. True at the beginning of an iteration
2. Remains true at the beginning of the next iteration

Thus to show that an invariant is true, we need to show 
1. Initialisation
2. Maintenance
3. Termination

## Correctness of Recursive Algorithm
Usually use MI on size of problem

> With simple induction you use "if ğ‘(ğ‘˜) is true then ğ‘(ğ‘˜+1) is true" while in strong induction you use "if ğ‘(ğ‘–) is true for all ğ‘– less than or equal to ğ‘˜ then ğ‘(ğ‘˜+1) is true", where ğ‘(ğ‘˜) is some statement depending on the positive integer ğ‘˜.

<!-- For anything smaller than n, binary search will return the correct answer as we assume strong induction -->

## Efficiency
**Tradeoff between simplicity and efficiency:** A naive simple algo is slower, while a fast algo tends to be complicated.

### How to design?
1. When the problem occurs a few times and small, use a simple algorithm.
2. When the problem occurs many times and big, use an efficient algorithm.

## Analysis of an algorithm
Indicators: 1) time and 2) space complexity

Two ways to analyze: 1) simulation and 2) mathematical analysis (calculating the running time)

## Asymptotic Analysis (Machine Independent Analysis)

**O-notation (upper bound)**
![O-notation](/assets/img/2020-16-1-CS3230/o-notation-graph.png)

We write \$ f(n) \exists O(g(n)) \$ if there exist **constants** *c > 0*, \$ n_0 > 0 \$ such that *0 â‰¤ f(n) â‰¤Â cg(n)* for all \$ n â‰¥ n_0 \$

> *O(g(n))* is actually a set of functions

**Omega-notation (lower bounds)**
**Intuition:** *f(n)* can never be faster than lower bound for given *n*
![Omega-notation](/assets/img/2020-16-1-CS3230/omega-notation-graph.png)

\$ \Omega(g(n)) \$ = { *f(n):* there exist positive constants *c* and \$ n_0 \$ such that *0 â‰¤Â cg(n) â‰¤ f(n)* for all n â‰¥ \$ n_0 \$}


<!-- Graph is incorrect no? Shud begin from n_0 -->
