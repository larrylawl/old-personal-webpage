---
layout: post
title: "TReNDS Kaggle Competition"
author: "Larry Law"
categories: unpublished
# tags: [machine-learning]
image: kaggle.png
hidden: true
---
# Five Steps to win a DL Competition
1. Understand the data
- [x] Find better workflow
- [ ] Check if `train_trends` is able to train and predict
  - [ ] Consider checking if i can run the model locally 
  - [ ] Check if it's okay to train with a subset of data each time (i'll only get 750...)
  - [ ] Not sure if I should still go on with this competition given that I need to change my data...
  - [ ] Tidy up the constant changing of roots :(
- [ ] Data Preparation
  - [ ] Convert `.mat` to `.npy`.
    - [ ] Unable to convert. Got OS error
  - [ ] Handle NA: `.dropna()` removes a significant chunk of the dataset
  - [ ] How to obtain different plots of `.mat`? Generate more training data from there
- [ ] 

1. Build a strong baseline
2. Find the tricks
3. Ensemble
4. Pseudo-Labels

## Understand the data

# TODO
# Brainstorming
## Optimisation Objective
MEDAL. (learning comes later)

## TODO:
- [x] Problem: Val (site 1) and test distribution (site 1 and 2) are different.
  - [x] Performed KS test and there's only one that shows that the distribution between test and train is only different for one feature
  - [x] Based on KS test, site bias is significant in many features for the significant level. However, performing KS test on train and test set features showed that only one feature comes from a different distribution. This means that while site 1 and 2 have site bias, most of the test dataset comes from site 1 (thus having the samse distribution).
  - [x] Thus val and test distribution are largely the same.
- [ ] Overfitting is an issue
  - [ ] Train error is much lower than test error
  - [ ] High dimensions of FNC
  - [ ] Generating syn data from tabular data: https://github.com/sdv-dev/CTGAN
  - [ ] Grid search on C value of SVR?
- [ ] Consider using /500 instead (rank 1 is using that)
- [ ] Problem: `domain2_var2` and `domain2_var1` are not learning from fnc well enough. Identify important FNC features based on LOFO [here](https://www.kaggle.com/aerdem4/trends-lofo-feature-importance). Will definitely improve local CV but does not generalise well according to this [discussion](https://www.kaggle.com/c/trends-assessment-prediction/discussion/156725).
  - [x] Try with 1 predictor first. Generalise later. `domain2_var2.`
  - [x] Identify important features and achieve better CV. Ridge CV improved but the other two did not; overall cv remained the same. Technically reducing dim -> reduce overfitting However LB worsened by to 0.1596, suggesting that I lost information.
  - [ ] [IP] Clarify understanding as I thought removing dimensions will prevent overfitting
  - [ ] Regularise to achieve better LB
- [x] Removing site bias: IC20 is not used in prediction (same score when dropped or kept). Learning Point: Should use LOFO to identify features to work on first, before working on them; in this case I worked on an irrelevant feature.
  - [ ] Scale down distributions which are different. Purpose is to make val set similar to test set distribution.
- [ ] How to take advantage of correlation between variables and targets?
- [ ] Handle NAN values (in response at least)... imputation of everything doesn't seem to be working...
- [ ] AutoML soln to find best significance level / hyperparams in general?
  - [ ] Another day... takes awhile to code it out...
- [ ] NN doesn't seem to be working. (https://www.kaggle.com/c/trends-assessment-prediction/discussion/153256)

## Clues
1. **NN w/ category data:** Atom (0.1599)
2. SVR + Ridge: Excluding some features (0.15771)
3. Gunes: 

## Submission Format:
1. Changes:
2. Notebook name:
3. Version Number:
4. Scores:

## EDA Insights
1. **Site Bias in IC_20.** Filter out shifts? 
2. For Source-based morphomotery loadings' correlation, there are strong correlations between age and some loading features that exceed -0.4.
    1. Linear correlation? 
3. KS-test to determine classify examples to site 1 and 2. From there, determine distribution of training and test sets. From here, I can further change my val set distribution to match the test set.
    1. Possibly change KS threshold to the formula I used, though I think it'll have limited effect.
4. Trying to mimick validation and test distribution.

## Results
```
Removing unimportant variables and not scaling down important ones
For domain2_var2:
SVR: 0.177883
Ridge: 0.185118
BaggingRegressor: 0.174743
Ensemble: 0.175479
``

```
Removing unimportant variables and scaling down important ones
For age:
SVR: 0.144158
Ridge: 0.143463
BaggingRegressor: 0.15619
Ensemble: 0.142335

For domain1_var1:
SVR: 0.151293
Ridge: 0.1537
BaggingRegressor: 0.151566
Ensemble: 0.15067

For domain1_var2:
SVR: 0.151021
Ridge: 0.15582
BaggingRegressor: 0.151204
Ensemble: 0.15079

For domain2_var1:
SVR: 0.181687
Ridge: 0.185433
BaggingRegressor: 0.18241
Ensemble: 0.18116

For domain2_var2:
SVR: 0.177883
Ridge: 0.176647 -> decreased by 0.0034! but its because weightage is low so i can't tell
BaggingRegressor: 0.175256 
Ensemble: 0.175305

Overall score: 0.157837
CPU times: user 8min 21s, sys: 21.8 s, total: 8min 43s
Wall time: 8min 45s

```
# scaling by /1800 for unimportant features
For domain2_var2:
SVR: 0.17788
Ridge: 0.185118
BaggingRegressor: 0.174988
Ensemble: 0.175529

Overall score: 0.030718
CPU times: user 1min 38s, sys: 4.55 s, total: 1min 43s
Wall time: 1min 44s
```

```
# results for no scaling on fnc
For age:
SVR: 0.17624
Ridge: 0.160571
BaggingRegressor: 0.152364
Ensemble: 0.153991

For domain1_var1:
SVR: 0.155423
Ridge: 0.176112
BaggingRegressor: 0.153854
Ensemble: 0.15392

For domain1_var2:
SVR: 0.152812
Ridge: 0.179621
BaggingRegressor: 0.154902
Ensemble: 0.152892

For domain2_var1:
SVR: 0.184424
Ridge: 0.212837
BaggingRegressor: 0.185165
Ensemble: 0.184503

For domain2_var2:
SVR: 0.179571
Ridge: 0.206818
BaggingRegressor: 0.180393
Ensemble: 0.178962

Overall score: 0.163496
CPU times: user 8min 18s, sys: 27 s, total: 8min 45s
Wall time: 8min 48s
```

Optimisation Objective: Medal
Purpose of blogging:
1. What I've Done (concretely shows what I've learnt)
2. What I've Learnt
3. How I can improve for the next competition

(No one cares about the specifics of the progress lol, people only care about the end product.)

Purpose:
1. Journal of progress?
2. Write down what I've learnt? - can't I just do this at the end?

Hey! This article serves to document my progress in my first Kaggle competition, TReNDS Neuroimaging: multiscanner normative age and assessments prediction with brain function, structure, and connectivity. You can view more details [here](https://www.kaggle.com/c/trends-assessment-prediction/overview).

### 21052020 - First Submission

Submitted the baseline kernele kindly put together by ![Rohit Singh](https://www.kaggle.com/rohitsingh9990). Model uses ridge and svm regression. **Baseline score is 0.162. Rank of 231/378**.