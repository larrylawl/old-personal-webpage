---
layout: post
title: "NUS, CS3230: Design and Analysis of Algorithms"
author: "Larry Law"
categories: notes
image: cs.png
hidden: true
---
Lecturer: [Professor Sung Wing Kin](https://www.comp.nus.edu.sg/cs/bio/ksung/), [Professor Diptarka](https://www.comp.nus.edu.sg/cs/bio/diptarka/) <br>
Probability cheatsheet [here](https://static1.squarespace.com/static/54bf3241e4b0f0d81bf7ff36/t/55e9494fe4b011aed10e48e5/1441352015658/probability_cheatsheet.pdf).
List of common distribution properties [here](http://www.stat.tamu.edu/~twehrly/611/distab.pdf).

<!-- omit in toc -->
# Table of Contents
- [Questions](#questions)
- [Overview](#overview)
  - [Course Objectives](#course-objectives)
- [Correctness](#correctness)
  - [Reasoning and Asymptotic Analysis](#reasoning-and-asymptotic-analysis)
    - [What is a good algorithm?](#what-is-a-good-algorithm)
  - [Correctness of Iterative Algorithm](#correctness-of-iterative-algorithm)
  - [Correctness of Recursive Algorithm](#correctness-of-recursive-algorithm)
  - [Efficiency](#efficiency)
    - [How to design?](#how-to-design)
  - [Analysis of an algorithm](#analysis-of-an-algorithm)
  - [Asymptotic Analysis (Machine Independent Analysis)](#asymptotic-analysis-machine-independent-analysis)
- [Growth of Functions](#growth-of-functions)
  - [Exponentials](#exponentials)
  - [Logarithms](#logarithms)
    - [Stirling's Approximation](#stirlings-approximation)
  - [Summations](#summations)
  - [Limit](#limit)
    - [L'Hopital's Rule](#lhopitals-rule)
  - [Properties of Big O](#properties-of-big-o)
- [Divide-and-Conquer](#divide-and-conquer)
  - [Substitution Method for solving recurrences](#substitution-method-for-solving-recurrences)
  - [Telescoping method](#telescoping-method)
  - [Recursion Tree](#recursion-tree)
  - [Master Method](#master-method)
  - [The divide-and-conquer design paradigm](#the-divide-and-conquer-design-paradigm)
  - [Summary of D&C example time complexities](#summary-of-dc-example-time-complexities)
- [Sorting in Linear Time](#sorting-in-linear-time)
  - [Sorting Lower Bound](#sorting-lower-bound)
  - [Linear-time sorting](#linear-time-sorting)
- [Randomized Algorithms](#randomized-algorithms)
  - [Universal Hashing](#universal-hashing)
- [QuickSort](#quicksort)
  - [Performance of QuickSort](#performance-of-quicksort)
  - [Randomized version of quicksort](#randomized-version-of-quicksort)
  - [Randomized Quicksort in practice](#randomized-quicksort-in-practice)
- [Order Statistics](#order-statistics)
  - [Selection in Expected Linear Time](#selection-in-expected-linear-time)
- [Amortized Analysis](#amortized-analysis)
  - [Types of Amortized Analysis](#types-of-amortized-analysis)
    - [Aggregate Analysis](#aggregate-analysis)
    - [Accounting Method](#accounting-method)
    - [Potential Method](#potential-method)
- [Dynamic Programming](#dynamic-programming)
  - [Dynamic Programming Algorithm Paradigm](#dynamic-programming-algorithm-paradigm)
- [Greedy Algorithms](#greedy-algorithms)
  - [Paradigm for greedy algorithms](#paradigm-for-greedy-algorithms)
  - [Prefix Code and Labelled Binary Tree](#prefix-code-and-labelled-binary-tree)
- [Reductions & Intractability](#reductions--intractability)
  - [What is a reduction?](#what-is-a-reduction)
  - [p(n)-time Reduction](#pn-time-reduction)
  - [Running Time Composition](#running-time-composition)
  - [Polynomial-Time Reduction](#polynomial-time-reduction)
  - [Decision Problems](#decision-problems)
    - [Vertex Cover and Independent Sets](#vertex-cover-and-independent-sets)
    - [Hamiltonian Cycle and TSP](#hamiltonian-cycle-and-tsp)
- [NP-Completeness](#np-completeness)
  - [NP Class](#np-class)
  - [NP Complete](#np-complete)
  - [Satisfiability (CNF-SAT)](#satisfiability-cnf-sat)
  - [How to show a problem to be NP-complete](#how-to-show-a-problem-to-be-np-complete)
- [Approximation Algorithms](#approximation-algorithms)
  - [Approximation Ratio](#approximation-ratio)
  - [Two General Approaches](#two-general-approaches)

# Questions
1. What's cut-and-paste argument?

# Overview
## Course Objectives
1. Learns tools to analyse the performance of algorithms
2. Learns techniques to design an efficient algorithm.

# Correctness
## Reasoning and Asymptotic Analysis
### What is a good algorithm?
1. Correct
2. Efficient
3. Well-documented and with sufficient details
4. Maintainable

## Correctness of Iterative Algorithm

**Loop Invariant**
1. True at the beginning of an iteration
2. Remains true at the beginning of the next iteration

How to use invariant to show the correctness of an iterative algorithm? 
1. **Initialisation:** The invariant is true before the first iteration of the loop
2. **Maintenance:** If the invariant is true before an iteration, it remains true before the next iteration
3. **Termination:** When the algorithm terminates, the invariant provides a useful property for showing correctness.

## Correctness of Recursive Algorithm
Usually use MI on size of problem
1. Base Case
2. Inductive Step: Using the inductive hypothesis, show that the next step is true.  

> With simple induction you use "if 𝑝(𝑘) is true then 𝑝(𝑘+1) is true" while in strong induction you use "if 𝑝(𝑖) is true for all 𝑖 less than or equal to 𝑘 then 𝑝(𝑘+1) is true", where 𝑝(𝑘) is some statement depending on the positive integer 𝑘.

## Efficiency
**Tradeoff between simplicity and efficiency:** A naive simple algo is slower, while a fast algo tends to be complicated.

### How to design?
1. When the problem occurs a few times and small, use a simple algorithm.
2. When the problem occurs many times and big, use an efficient algorithm.

## Analysis of an algorithm
Indicators: 1) time and 2) space complexity

Two ways to analyze: 1) simulation and 2) mathematical analysis (calculating the running time)

## Asymptotic Analysis (Machine Independent Analysis)

**O-notation (upper bound)**
![O-notation](/assets/img/2020-16-1-CS3230/o-notation-graph.png)

> *O(g(n))* is actually a set of functions

> O-notation vs o-notation: ≤ vs <

**Omega-notation (lower bounds)**
**Intuition:** *f(n)* can never be faster than lower bound for given *n*
![Omega-notation](/assets/img/2020-16-1-CS3230/omega-notation-graph.png)

> Omega-notation vs omega-notation: ≥ vs >

**Theta-notation (tight bounds)**
![Theta-notation](/assets/img/2020-16-1-CS3230/theta-notation-graph.png)

**Common time complexities.**

![Common Time Complexities](/assets/img/2020-16-1-CS3230/common-time-complexities.png)

$$
n^{(1 / \lg n)}<<n(\lg \lg n)<<\lg (n !) \equiv 3 \text { n }(\lg n) \\ 
<<(\lg n) ! \equiv 2^{\theta(lgn lglgn)} \equiv \theta(n) <<n^{\lg n}<<2^{n}-n^{2} << (\lg n)^n << n!
$$

<!-- TODO: Add in stirling's complexity into the classes -->

# Growth of Functions
## Exponentials

$$
\begin{aligned} a^{-1} &=1 / a \\\left(a^{m}\right)^{n} &=a^{m n} \\ a^{m} a^{n} &=a^{m+n} \\ e^{x} & \geq 1+x \end{aligned}
$$

1. **Any exponential function with base a > 1 grows faster than any polynomial**
   1. Lemma: For any constants *k > 0* and *a > 1*, \$ n^k = o(a^n) \$

## Logarithms

$$
\begin{aligned} a &=b^{\log _{b} a} \\ \log _{c}(a b) &=\log _{c} a+\log _{c} b \\ \log _{b} a^{n} &=n \log _{b} a \\ \log _{b} a &=\frac{\log _{c} a}{\log _{c} b} \\ \log _{b}(1 / a) &=-\log _{b} a \\ \log _{b} a &=\frac{1}{\log _{a} b} \\ a^{\log _{b} c} &=c^{\log _{b} a} \end{aligned}
$$

1. Base of log does not matter in asymptotics (can use change of bases, and one of which will be a constant)

### Stirling's Approximation
Tighter upper bound for factorial

$$
\begin{array}{l}{n !=\sqrt{2 \pi n}\left(\frac{n}{e}\right)^{n}\left(1+\Theta\left(\frac{1}{n}\right)\right)} \\ {\log (n !)=\Theta(n \lg n)}\end{array}
$$

> Important for exams. Particularly the time complexity!

## Summations
Arithmetic Series

$$
S_n = \frac{n}{2}[2a + (n - 1)d]
$$

Geometric Series

$$
S_n = \frac{a(r^n-1)}{r - 1} \\
S_{\infty} = \frac{a}{1-r}
$$

Harmonic Series

$$
\begin{aligned} H_{n} &=1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\cdots+\frac{1}{n} \\ &=\sum_{k=1}^{n} \frac{1}{k} \\ &=\ln n+O(1) \end{aligned}
$$

> Important for exams

Telescoping Series

$$
\begin{aligned} \sum_{k=1}^{n-1} \frac{1}{k(k+1)} &=\sum_{k=1}^{n-1}\left(\frac{1}{k}-\frac{1}{k+1}\right) \\ &=1-\frac{1}{n} \end{aligned}
$$

## Limit

$$
\begin{array}{l}{\text { Assume } \mathrm{f}(\mathrm{n}), \mathrm{g}(\mathrm{n})>0} \\ {\lim _{n \rightarrow \infty}\left(\frac{f(n)}{g(n)}\right)=0 \rightarrow f(n)=o(g(n))} \\ {\lim _{n \rightarrow \infty}\left(\frac{f(n)}{g(n)}\right)<\infty \rightarrow f(n)=O(g(n))} \\ {0<\lim _{n \rightarrow \infty}\left(\frac{f(n)}{g(n)}\right)<\infty \rightarrow f(n)=\Theta(g(n))} \\ {\lim _{n \rightarrow \infty}\left(\frac{f(n)}{g(n)}\right)>0 \rightarrow f(n)=\Omega(g(n))} \\ {\lim _{n \rightarrow \infty}\left(\frac{f(n)}{g(n)}\right)=\infty \rightarrow f(n)=\omega(g(n))}\end{array}
$$

### L'Hopital's Rule
$$
\lim_{x \to \inf}\frac{f(x)}{g(x)} = \lim_{x \to \inf}\frac{f'(x)}{g'(x)} 
$$

## Properties of Big O
![Properties of big O](/assets/img/2020-16-1-CS3230/properties-big-o.png)

# Divide-and-Conquer
How to analyze the running time of a recursive algo?
1. Derive a recurrence
2. Solve the recurrence

## Substitution Method for solving recurrences
The most general method:
1. Guess the form of the solution
2. Verify by induction

> Don't verify inductive hypothesis with O-notation. e.g. Verifying \$ T(k) = c • k^2 \$ with \$ O\(k^2\) \$.

**Common Recurrences solved by Substitution Method**
1. \$ T(n) = T(n - 2) + T(n - 1) + a = \Theta(F_n) \$
2. \$ T(n) = 4 T(n/2) + n = O(n^3) \$

**Heuristics to making a good guess**
1. Use recursion trees to generate good guesses
2. Prove loose upper and lower bounds on the recurrence and then reduce the range of uncertainty

## Telescoping method
![Telescoping method](/assets/img/2020-16-1-CS3230/telescoping-method.png)

## Recursion Tree
![Recursion Tree](/assets/img/2020-16-1-CS3230/recursion-tree.png)

## Master Method
Let *a ≥ 1* and *b > 1* be constants, let *f* to be asymptotically positive, and let T(n) be defined on the non negative integers by the recurrence

$$
T(n) = aT(n/b) + f(n), where
$$

> we interpret *n/b* to mean either floor(*n/b*) or ceiling(*n/b*).

> **a**: # subproblems, **n/b:**  subproblem size, **f(n):** work dividing and combining

Then *T(n)* has the following asymptotic bounds:

1. If \$ f(n) = O(n^{log_ba-\epsilon}) \$ for some constant \$ \epsilon > 0 \$, then \$ T(n) = \Theta(n^{log_ba}) \$
2. If \$ f(n) = \Theta(n^{log_ba}) \$, then \$ T(n) = \Theta(n^{log_ba}lgn) \$
3. If \$ f(n) = \Omega(n^{log_ba+\epsilon}) \$ for some constant \$ \epsilon > 0 \$, and if \$ af(n/b) ≤ cf(n) \$ for some constant *c < 1* and all sufficiently large n, then \$ T(n) = \Theta(f(n)) \$

> In the third case, *af(n/b) ≤ cf(n)* is also called the *regularity condition*

**Intuition:** All three cases are comparing the function *f(n)* with the function \$ n^{log_ba} \$. Intuitively, the larger of the two function determines the solution to the recurrence. 
1. **Case 1:** When \$ n^{log_ba} \$ is **polynomially bigger** (ie \$ \frac{n^{log_ba}}{f(n)} = n^{\epsilon},  \epsilon > 0 \$)
2. **Case 2:** When they are the same size, thus we multiply by a logarithmic factor *lgn* to obtain \$ T(n) = \Theta(n^{log_ba}lgn) = \Theta(f(n)lgn) \$.
3. **Case 3:** When *f(n)* is **polynomially bigger**


> Note that these three cases do not cover all possibilities for *f(n)*. The gaps are...

1. Between case 1 and 2: when f(n) is smaller than \$ n^{log_ba} \$, but **not polynomially smaller**
2. Between case 2 and 3: when f(n) is bigger than \$ n^{log_ba} \$, but **not polynomially bigger**

> What about \$ \frac{f(n)}{n^{log_ba}} = \frac{1}{2^n} \$ (ie f(n) is exponentially smaller than \$ n^{log_ba} \$)? 

Yes. Case 1 of MT.

$$
f(n) = \frac{n^{log_ba}}{2^n} = O(n^{log_ba - \epsilon}), where \epsilon < log_ba
$$

**Example Questions**
Recurrence relation that has *cos*.

![Master's Theorem with cos](/assets/img/2020-16-1-CS3230/master-theorem-cos.png)

## The divide-and-conquer design paradigm
1. **Divide** the problem into subproblems
2. **Conquer** the subproblems by solving them *recursively*
3. **Combine** subproblem solutions

Challenge is in categorising the problem into the three steps. Example:

![power number](/assets/img/2020-16-1-CS3230/power-number.png)

<!-- Q: Diagonalise matrix -> no need to compute power -> O(1) time? -->

## Summary of D&C example time complexities
![dnc examples](/assets/img/2020-16-1-CS3230/dnc-examples.png)

> Note that master method can be used to analyse the complexity (so practice the math)

# Sorting in Linear Time
**Classfication of the sorting algorithm** 
1. **In-Place:** If it uses very little additional memory beyond that used for the data (usually \$ O(1) \$ or \$ O(lg n) \$). (thus it is sorting in the place of the data)
2. **Stable:** If the original order of equal elements is preserved in the sorted output
3. **Comparison:** Sort the elements by comparing them only

## Sorting Lower Bound
**Decision Tree Model.** A decision tree can model the execution of *any* comparison sort.
1. One tree for each input size *n*
2. Tree contains the comparisons along all possible instruction traces
3. Run-time = length of the path taken
4. Worse-case run time = height of tree

**Lower Bound for decision-tree sorting** <br />
**Theorem.** Any decision tree that can sort *n* elements must have height \$ \Omega(nlgn) \$.

**Proof.** (it's important as it's commonly used)
1. n! permutations => Can find \$ n_1, n_2, \cdots, n_n \$ such that the sorting process results in an order of \$ n_i \in n! \$ permutations =>  Decision tree must contain ≥ n! leaves
2. Height-*h* binary decision tree has \$ \leq 2^h \$  leaves. Thus, \$ n! \leq 2^h \$.

$$
\begin{align*}
h &\geq lg(n!) (\text{lg is mono. increasing}) \\
  &\geq lg((\frac{n}{e})^n) (\text{Stirling's formula}) \\
  &= nlgn - nlge \\
  &= \Omega(nlgn)
\end{align*}
$$

> Why does height-h binary tree have \$ \leq 2^h \$ leaves?

Every node has at most 2 successors (since it's a binary tree). Thus the hth height has \$ 2^h \$ leaves.

> Further note that a binary decision tree with n **comparisons** ≤ \$ 2 ^ n \$ leaves (ie it has the same upper bound as a height-h decision tree). This is because every comparison only expands one node, whereas every increase in height expands *all* nodes of that level. Thus, if *n = h*, the number of leaves for a binary tree with *n* comparsions will be upper bounded by the number of leaves for a binary decision tree of height *h*.

**Corollary.** Heapsort and mergesort are asymptotically optimal *comparison* sorting algorithms.

> The sorting lower bound assumes we only compare elements. If we do more than comparison, we may be able to break the lower bound.

## Linear-time sorting
**Counting Sort.** Link [here](https://www.geeksforgeeks.org/counting-sort/).
![Counting Sort Analysis](/assets/img/2020-16-1-CS3230/counting-sort-analysis.png)

Properties.
1. Stable
2. No comparison

**Radix Sort** Link [here](https://www.geeksforgeeks.org/radix-sort/).


**Lemma 8.3** Given *n d-*digit numbers in which each digit can take on up to *k* possible values, \$ RADIX-SORT \$ correctly sorts these numbers in \$ \Theta(d(n + k)) \$ time if the stable sort it uses takes \$ \Theta(n + k) \$.

When d is constant and \$ k = O(n) \$, we can make radix sort run in linear time. *More generally, we can have some flexibility in how to break each key into digits.*

> Key is equivalent to the number of digits in a number; you perform counting sort on each key

**Lemma 8.4.** Given *n b-*bit numbers and any positive integer \$ r \leq b \$, \$ RADIX-SORT \$ correctly sorts these numbers in \$ \Theta((b/r)(n + 2^r)) \$ time if the stable sort it uses takes \$ \Theta(n + k) \$ time for inputs in the range 0 to k.

> For a value \$ r \leq b \$, we view each key as having \$ d = \lceil b / r \rceil \$ digits of *r* bits each. Since each digit is an integer in the range 0 to \$ 2^r - 1 \$ (since r bits can represent \$ 2^r \$ numbers), we can use counting sort with \$ k = 2^r - 1 \$ with *d* passes.

1. If \$ b < \lfloor lgn \rfloor \$, then choosing r = b (since r ≤ b) yields a running time of \$ (\frac{b}{b})(n + 2^b) = \Theta(n) \$, which is asymptotically optimal.
2. If \$ b \geq \lfloor lgn \rfloor \$, then choosing \$ r = \lfloor lgn \rfloor \$ yields a running time of \$ \Theta (\frac{bn}{lgn}) \$.
  
**Drawback.** 
1. Radix sort is not in place whereas many \$ \Theta(nlgn) \$-time comparison sorts do. Thus when memory storage is at a premium, we might prefer an in-place algorithm.

> So should you use radix sort in preference to merge sort?

1. If comparison is O(1), then we should use merge sort.
2. If comparison is not O(1) (which is the case in today's computers as every number is stored with \$ 2^{64} \$ digits), then we should use radix sort (since it doesn't compare!)

# Randomized Algorithms
**Definition.** An algorithm is randomized if its behavior is determined not only by its input but also by values produced by a random-number generator.

**Monte Carlo Algorithm.** Randomized algorithm that gives the correct answer with probability \$ 1- o(1) \$ ("high probability"), but the runtime bounds hold deterministically.

**Las Vegas Algorithm.** Randomized algorithm that always gives the correct answer, but the runtime bounds depend on the random numbers.

**Average Running Time vs Expected Running Time** <br />
**Expected Running Time.** Expectation of the running time over the distribution of *values returned by the random number generator.* (randomized algo)

**Average Running Time.** Probability distribution *over the inputs to the algorithm.*

**Simple Uniform Hashing.** Any given element is equally likely to hash into any of the *m* elements, independently of where any other element has hashed to.

**Theorem 11.1.** In a hash table in which collisions are resolved by chaining, an **unsuccessful** search takes average-case time \$ \Theta(1 + \alpha) \$, under the assumption of simple uniform hasing.

> Unsucessful search: no element in the table has key *k*

**Theorem 11.2.** In a hash table in which collisions are resolved by chaining, a **successful** search takes average-case time \$ \Theta(1+ \alpha) \$, under the assumption of simple uniform hashing.

## Universal Hashing
**Motivation.** Any fixed hash function is vulnerable to an adversary choosing *n* keys that all hash to the same slot, yielding an average retrieval time of \$ \Theta(n) \$. The only effective way to improve the situation is to choose the hash function randomly in a way that is independent of the keys that are actually going to be stored. 

**Definition.** For any two distinct keys *x* and *y* from universe *U* of keys in the range \$ \{0, 1, \cdots, m - 1 \} \$,

$$
P(h(x) = h(y)) \leq \frac{1}{m}
$$

where the probability is over the random choice of the hash function $ h: U \rightarrow [m] \$.

> Universal hashing

**Theorem 11.3.**  Suppose that a hash function *h* is chosen randomly from a universal collection of hash functions and has been used to hash *n* keys into a table *T* of size *m* using chaining to resolve collisions. 
1. If key *k* is not in the table, then the expected length \$ E[n_{h(k)}] \$ of the list that key *k* hashes to is at most the load factor \$ \alpha = n/m \$. 
2. If key *k* is in the table, then \$ E[n_{h(k)}] \$ of the list containing key *k* is at most \$ 1 + \alpha \$.

**Corollary 11.4.** Using universal hashing and collision resolution by chaining in an intially empty table with *m* slots, it takes expected time \$ \Theta(n) \$ to handle any sequence of *n* \$ INSERT, SEARCH, DELETE \$ operations containing \$ O(m) INSERT \$ operations.

# QuickSort
```py
def Quicksort(A, p, r):
  if p < r
    q = Partition(A, p, r)
    Quicksort(A, p, q - 1)
    Quicksort(a, q + 1, r)
```

> To sort an entire array *A*, the initial call is `Quicksort(A, 1, A.length`.

## Performance of QuickSort
**Worse-Case Partition**
Occurs when the partitioning routine reduces one subproblem with *n - 1* elements and one with 0 elements.

$$
\begin{aligned} T(n) &=T(n-1)+T(0)+\Theta(n) \\ &=T(n-1)+\Theta(n) \end{aligned}
$$

Use the substitution method to show that this recurrence relation has the solution \$ T(n) = \Theta(n^2) \$

**Best-case partioning**

$$
T(n) = 2T(n/2) + \Theta(n)
$$

where we tolerate the sloppiness from ignoring the floor and ceiling and from subtracting 1. By case 2 of the Master Theorem, this recurrence has the solution \$ T(n) = \Theta(nlgn) \$.

**Balanced partitioning** <br />
Suppose that the partitioning algorithm always produces a 9-to-1 proportional split.

1. Notice that every level of the tree has cost *cn*, until the recursion reaches a boundary condition at depth \$ log_{10}n = \Theta(lgn) \$, and then the levels have cost at most *cn*. 
2. The recursion terminates at depth \$ log_{10/9}(n) = \frac{log_{10}n}{log_{9}1} = clog_{10}n = \Theta(lgn) \$. The total cost of quicksort is therefore \$ O(nlgn) \$. (Even a 99-to-1 split yields an \$ O(nlgn) \$ running time because a change of base will yield you a constant!)

## Randomized version of quicksort

```py
def Randomized-Partition(A, p, r)
  i = Random(p, r)
  exchange A[r] with A[i]
  return Partition(A, p, r)

def Randomized-Quicksort(A, p, r)
  if p < r
    q = Randomized-Partition(A, p, r)
    Randomized-Quicksort(A, p, q - 1)
    Randomized-Quicksort(A, q + 1, r)
```

**Lemma 7.1.** Let *X* be the number of comparisons made in line 4 of `Partition` (ie `if A[j] ≤ x`) over the entire execution of `Quicksort` on an *n*-element array. Then the running time of `Quicksort` is \$ O(n + X) \$

1. In the worse case, the algorithm makes at most *n* calls to `Partition`, each of which does a constant amount of work and then executes the`for` loop some number of times. Each iteration of the `for` loop executes line 4.
2. Our goal is to compute X.

$$
E[X] = O(nlgn) 
$$

> Shown in p. 182 - 184 of textbook.

## Randomized Quicksort in practice
1. **Las Vegas algorithm:** it always returns the correct solution
2. Randomized quicksort is typically over twice as fast as merge sort
3. Randomized quicksort can benefit substantially from *code tuning* 
4. Randomized quicksort behaves well even with caching and virtual memory

# Order Statistics
**Problem.** Given an unsorted list of *n* elements, the *ith* order statistics is the *ith* smallest element, or the *rank i* element.

Selecting the *ith* smallest element requires at least \$ \Omega(n) \$. 

## Selection in Expected Linear Time

**Randomized Quick-Select**
```py
Randomized-Select(A, p, r, i) # A[p...r]
if p == r
  return A[p]
q = Randomized-Partition(A, p, r)
k = q - p + 1
if i == k # pivot value is the answer
  return A[q]
elif i < k
  return Randomized-Select(A, p, q - 1, i)
else
  return Randomized-Select(A, q + 1, r, i - k)
```

$$
E[T(n)] = \frac{2}{n} \sum^{n - 1}_{k = \lfloor n/2 \rfloor} E[T(k)] + \Theta(n) \leq cn, c > 0
$$

> Proof in notes uses substitution method and...

$$
\sum^{n - 1}_{k = \lfloor n/2 \rfloor} k \leq \frac{3}{8} n^2
$$

<!-- Q: Don't understand fact ^ -->

**Worse Case:** \$ \Theta(n^2) \$. Is there an algorithm that runs in linear time in the worst case?

**Worst-Case Linear Time Select** <br />
**Intuition.** Generate a good pivot recursively.

![Select Algorithm](/assets/img/2020-16-1-CS3230/select.png)

1. For n ≥ 50, we have \$ 3 \lfloor \frac{n}{10} \rfloor \geq \frac{n}{4} \$. Thus in step 4, the subproblem size is reduced to \$ T(3n/4) \$

$$
T(n) = T(\frac{1}{5}n) + T(\frac{3}{4}n) + \Theta(n) \leq cn
$$

if *c* is chosen large enough to handle both the \$ \Theta(n) \$ and the initial conditions.

2. For n < 50, n is constant, thus \$ T(n) = \Theta(1) \$

> In practice, this algorithm runs slowly as the coefficient *c* is large. 

**Lemma.** Let x be the median of a set of points \$ p_1, \cdots, p_n \$ on the real line. f(y) ≥ f(x) for any y, where f(y) is defined as

$$
f(y) = \sum^n_{i = 1}|p_i -y|
$$

# Amortized Analysis
**Motivation.** The motivation for amortized analysis is that looking at the worst-case run time per operation (worst case analysis), rather than per algorithm, can be too pessimistic.

**Definition.**  Amortized analysis is a strategy for analyzing a sequence of operations to show that the **average** cost per operation is small, even though a single operation within the sequence might be expensive.

An amortized analysis guarantees the **average** performance of each operation in **the worst case.**

> Since it's worst case, no probability is involved.

When we say that an operation is amortized \$ \theta(1) \$, we mean that *n* operations run in total \$ \theta(n) \$ time in the worst case.

## Types of Amortized Analysis
1. **Aggregate Method** 
2. **Accounting Method**
3. **Potential Method**

> The aggregate method, though simple, lacks the precision of the other two methods. In particular, the accounting and potential methods allow a specific amortized cost to be allocated to each operation.

### Aggregate Analysis
In aggregate analysis, we show that for all n, a sequence of n operations takes worst-case time T(n) in total. In the worst case, the average cost, or amortized cost, per operation is therefore \$ T(n) / n \$.


### Accounting Method
**Intuition.** Impose an extra charge on inexpensive operations and use it to pay for expensive operations later on.

**Framework.**
1. Set amortised cost (ie `charge $2 for each 0 -> 1`).

$$
\forall n \in N: t(n) \leq \sum^n_{i = 1}c(i) \text{ (earning) } - \sum^{n - 1}_{i = 1}t(i) \text{ (expenditure) } \\
\sum^n_{i = 1}t(i) \text{ (total true costs) } \leq \sum^n_{i = 1}c(i) \text{ (total amortized costs)}
$$

1. Conclusion
    1. Amortized cost for each `%o := operation or sequence of operations` = 2 = \$ O(1) \$
    2. Amortized cost for n `%o` = 2n = \$ O(n) \$
    3. Actual cost for n `%o`  = \$ O(n) \$ (since Actual cost ≤ Amortized cost)

<!-- 1. Thus, for any sequence of n `PUSH, POP, and MULTIPOP` operations, the total amortized cost is an upper bound on the total actual cost. Since the total amortized cost is \$ O(n) \$, so is the total actual cost.
2. (If needed) Actual cost for 1 operation = \$ O(1) \$ -->

### Potential Method
Instead of representing prepaid work as credit stored with specific objects in the data structure, the potential method of amortized analysis represents the prepaid work as “potential energy,” or just “potential,” which can be released to pay for future operations. We associate the potential with the data structure as a whole rather than with specific objects within the data structure (difference between accounting and potential method).

1. \$ \phi \$: Potential function associated with the algorithm
    1. \$ \phi(i) \$: Potential at the end of ith operation
    2. \$ \phi(0) = 0 \$
    3. \$ \forall i: \phi(i) \geq 0 \$
2. Amortized cost of ith operation := Actual cost of ith operation + \$ \phi(i) - \phi(i - 1) \$ (also known as the potential difference)
3. Amortized cost of n operations ≥ Actual cost of n operations
4. If we want to show that actual cost of n operations is O(g(n)) then it suffices to show that amortized cost of n operations is O(g(n))

> Intuitively, if the potential difference \$ \phi(i) - \phi(i - 1) \$ of the ith operation is positive, then the amortized cost represents an overcharge to the ith operation. If the potential difference is negative, then the amortized cost represents an undercharge to the ith operation.

**Potential Method - Recipe**
1. For the **costly** operation, potential difference \$ \Delta\phi_i \$ is negative in order to nullify the effect of actual cost.
2. Try to view carefully the costly operation and see if there is some quantity that is **decreasing** during the operation. Why? Decreasing => \$ \phi_{i} < \phi_{i - 1} \$ => \$ \Delta \phi_i \$ is negative.

![Potential Method Example](/assets/img/2020-16-1-CS3230/potential-method-eg.png)

Amortized cost of n operations (ie insertions) = 3n = O(n) \\
Actual cost of n operations = O(n)

# Dynamic Programming
1. Dynamic programming, like the divide-and-conquer method, solves problems by combining the solutions to subproblems.
2. Divide-and-conquer algorithms partition the problem into disjoint subproblems, solve the subproblems recursively, and then combine their solutions to solve the original problem. 
3. In contrast, dynamic programming applies when the subproblems overlap—that is, when subproblems share subsubproblems.
4. In this context, a divide-and-conquer algorithm does more work than necessary, repeatedly solving the common subsubproblems. A dynamic-programming algorithm solves each subsubproblem just once and then saves its answer in a table, thereby avoiding the work of recomputing the answer every time it solves each subsubproblem.

> (“Programming” in this context refers to a tabular method, not to writing computer code.)

**Definition.** (optimal substructure) An optimal solution to a problem (instance) contains optimal solutions to subproblems

**Coin Change Problem.** We have *n* cents and need to get change in terms of denominations \$ d_1, d_2, \cdots, d_k \$. Goal is to use the fewest total number of coins. Let M[j] be the fewest number of coins needed to change *j* cents.

![Optimal Substructure Eg](/assets/img/2020-16-1-CS3230/optimal-substructure-eg.png)

Here, the optimal solution M[j] contains the optimal solution to subproblem minM[j - d_i]. 

**Cut-And-Paste argument.** The "cut and paste" technique is a way to prove that a problem has this property. In particular, you want to show that when you come up with an optimal solution to a problem, you have necessarily used optimal solutions to the constituent subproblems. The proof is by contradiction. Using the example above,
1. The recurrence relation is the optimal substructure.
2. Suppose M[j] = t
3. Cut the optimal solution out and paste \$ M[j'] < t - 1 \$ in.
4. Cut and pasting improves the optimal solution, \$ M[j] < t \$. (contradiction)

**Definition.** (subsequence) *C* is said to be a **subsequence** of *A* if we can obtain *C* by removing 0 or more elements form A.

E.g.
1. A: a,b, a, d, e, b, c, a
2. C: a, a, e, b, a

## Dynamic Programming Algorithm Paradigm
1. Expressing the solution **recursively**
2. Overall, there are only **polynomial number of distinct subproblems**
3. But there is a **huge overlap** among the subproblems. So the recursive algorithm takes exponential time (solving the same subproblem multiple times)

**Definition.** (overlapping subproblems) A recursive solution contains a "small" number of distinct subproblems repeated many times.

E.g.
(n + 1) * (m + 1) distinct subproblems for \$ L(n, m) \$

4. So we compute the recursive solution **iteratively in a bottom-up fashion** (like in the case of Fibonacci numbers). This avoids wastage of computation and leads to an efficient implementation.

> Dynamic programming on topological ordering (but reverse order)

**Top-down vs Bottom-up** <br />
**Top-Down** approach solves the recurrence only when needed to <br />
**Bottom-Up** (eg case of Fibonacci numbers) solves all recurrences.

# Greedy Algorithms
**Intuition.** Recast the problem so that **only one subproblem** needs to be solved at each time. Beats divide-and-conquer and dynamic programming, **when it works.**

## Paradigm for greedy algorithms
1. Cast the problem where we have to **make a choice and are left with one subproblem** to solve.
2. Prove that there is always an **optimal solution to the original problem that makes the greedy choice,** so the greedy choice is safe using **exchange argument** (ie swap the greedy choice with some optimal solution and show that solution is still optimal).
3. Use **optimal substructure** to show that we can combine an optimal solution to the subproblem with the greedy choice to get an optimal solution to the original problem (using cut-and-paste argument).

**Greedy Choice** (point 2)
![Greedy Choice](/assets/img/2020-16-1-CS3230/greedy-choice-eg.png)

**Greedy Optimum Substructure** (point 3)
![OS](/assets/img/2020-16-1-CS3230/greedy-os-eg.png)

## Prefix Code and Labelled Binary Tree
**Definition.** A coding \$ \gamma(A) \$ is called prefix coding if there does not exist \$ x, y \in A \$ such that

$$
\gamma(x) \text{ is prefix of } \gamma(y)
$$

**Algorithmic Problem.** Given a set *A* of *n* alphabets and their frequencies, computing coding \$ \gamma \$ such that
1. \$ \gamma \$ is prefix coding
2. \$ ABL(\gamma) \$ is minimum

> ABL is Average Bit Length per symbol

**Theorem.** For each prefix code of a set *A* of *n* alphabets, there exists a binary tree *T* on *n* leaves such that 
1. There is a **bijective mapping** between the alphabets and the leaves
> Bijective: one-to-one
2. The **label of a path from root to a leaf** node corresponds to the **prefix code** of the corresponding alphabet

**Lemma.** The binary tree corresponding to optimal prefix coding must be a **full binary tree:** every internal node has degree exactly 2.

**Lemma.** There **exist an optimal** prefix coding in which \$ a_1, a_2 \$ (least frequenct alphabets) appear as **sibilings** in the corresponding labeled binary tree.

> It is inaccurate to claim that in **every optimal prefix coding,** \$ a_1, a_2 \$ appear as siblings in the labeled binary string.

# Reductions & Intractability
## What is a reduction?
Consider two problems *A* and *B*. *A* can be solved as follows:
1. Input an instance \$ \alpha \$ of A
2. Solve \$ \beta \$ and obtain a solution
3. Based on the solution of \$ \beta \$, obtain the solution of \$ \alpha \$.
4. Then, we say **A reduces to B**

![Reduction Diagram](/assets/img/2020-16-1-CS3230/reduction-diagram.png)

> E.g: *MAT-SQR* reduces to *MAT-MULTI* means that *MAT-SQR* can be converted to *MAT-MULTI* (Given input matrix C for *MAT-SQR*, let A = B = C be the inputs for *MAT-MULTI*). Then solve *MAT-MULTI*.

## p(n)-time Reduction

Consider two problems *A* and *B*.

If for any instance \$ \alpha \$ of problem *A* of size *n*:
1. An instance \$ \beta \$ for problem *B* can be constructed in *p(n)* time
2. A solution to problem *A* for input \$ \alpha \$ can be recovered from a solution to problem *B* for input \$ \beta \$ in time *p(n)*.

> Its the conversion (first from \$ \alpha \$ to \$ \beta \$, then from \$ B(\beta) \$ to \$ A(\alpha) \$) that takes *p(n)*

Then, we can say that there is a **p(n)-time reduction from A to B**.

## Running Time Composition
**Claim.** If there is a *p(n)-*time reduction from **problem A to problem B**, and there exist a **T(n)-time algorithm to solve problem B** on instances of **size n**, then there is a 

$$
T(p(n)) + O(p(n))
$$

time algorithm to solve problem *A* on instances of **size n**.

> p(n) (converting) + T(p(n)) (solving) + p(n) (converting back) = T(p(n)) + O(p(n))

## Polynomial-Time Reduction
**Definition.** (polynomial time) For polynomial time, we mean that the runtime is polynomial in the **length of the encoding of the problem instance**.

For example, if the length of the encoding of the problem instance is *logn*, then the algorithm is polynomial time if the runtime is *poly(logn)*.

An algorithm that runs in polynomial time in the numeric value of the input but is exponential in the length of the input is called a **pseudo-polynomial time** algorithm.

**Example.** (Fib(n)). n is the numeric value of the input. But x = logn is the number of bits to represent this numeric value. 

$$
O(n) = O(n^{log_22}) = O(2^{log_2n}) = O(2^x) \\
T(x) = O(2^x)
$$

Thus Fib(n) is O(n) in terms of instructions, but \$ O(2^x) \$ in terms of bits.

**Example 2.** Knapsack and Fractional Knapsack.
1. Input size is a list \$ (v_1, w_1), \cdots, (v_n, w_n), W \$. Thus input size = \$ O(nlogM + log W) \$, where M is an upper bound on the \$ v_i \$ and \$ w_i \$.
2. Running time for Knapsack = nW enries \* logM each = \$ O(nWlogM) > poly(nlogM) \$ 
3. Running time for fractional knapsack = \$ O(nlogWlogM) \leq poly(nlogM) \$ (since W is an integer)

**Definition.**

$$ 
A \leq_P B
$$

If there is a p(n)-time reduction from A to B for some polynomial function \$ p(n) = O(n^c) \$ for some constant c.

Thus, if B has a polynomial time algorithm T(n), then so does A. (Given by the claim above on time complexity of A: \$ T(p(n)) + O(p(n)) \$. Contrapositively, If A cannot be solved in polynomial time, then neither can B. (Intuitively, since A is reduced to B, A is a special case of B.)

> Why Poly-Time? 

Polynomial time algorithms are usually solvable in practice using "standard" computing hardware.

**Intractability:** Problems for which there exist no efficient algorithms to solve them.

## Decision Problems
**Decision Problem:** Function that maps an instance space *I* to the solution set {YES, NO}.

**Decision vs Optimisation problem.** Former: is there a path? Latter: what is the length of the shortest path?

**Reductions between Decision Problems.** <br />
Given two decision problems *A* and *B*, a **polynomial time reduction** from *A* to *B* denoted \$ A \leq_p B \$ is a transformation from instances \$ \alpha \$ of *A* to instances \$ \beta \$ of *B* such that
1. \$ \alpha \$ is a YES-instance for *A* **iff** \$ \beta \$ is a YES-instance for B.
> Since decision problems are binary, the statement is logically equivalent to \$ \alpha \$ is a NO-instance for *A* **iff** \$ \beta \$ is a NO-instance for B.
> Constructed B must remain the same in the bidirectional proof.
1. The transformation takes polynomial time in the size of \$ \alpha \$

### Vertex Cover and Independent Sets
**Definition.** (vertex covery) Given an undirected graph \$ G = (V, E) \$, a subset \$ X \subseteq V \$ is said to be a vertex cover if for each edge \$ (u, v) \in E \$, either \$ u \in X \$ or \$ v \in X \$.

**Definition.** (independent set) Given an undirected graph \$ G = (V, E) \$, a subset \$ X \subseteq V \$ is said to be an independent set if for each \$ u, v \in X, (u, v) \notin E \$.

**Theorem:** \$ X \subseteq V \$ is a vertex cover of *G* **iff** \$ V \backslash X \$ is an independent set of *G*

### Hamiltonian Cycle and TSP
**Definition.** (hamiltonian cycle) Given an undirected graph \$ G = (V , E) \$, a cycle is said to be Halmiltonian if it passes through **each** vertex.

**Definition.** (TSP) Given an undirected complete graph \$ G = (V, E) \$ with nonnegative cost on edges, a tour is a sequence of vertices such that
1. It originates and terminates at the same vertex
2. There is an edge between every consecutive pair of vertices in the sequence
3. Each vertex is visited **exactly** once
4. Cost of tour: Sum of cost of edges traversed in the tour.

**Theorem:** G has a Hamiltonian cycle iff G' has a TSP tour of cost at most *n*.

> With this theorem, what is the corresponding *f* to establish \$ HC \leq_P TSP \$?

1. On Input (G), f constructs G' using the theorem and outputs (G', n). f takes polynomial time. Hence \$ HC \leq_P TSP \$.

# NP-Completeness
## NP Class
1. **X:** Any decision problem
2. **I:** Any (input) instance of *X*
  
How to capture the fact that certifier *A* is efficient?

1. **Efficient Certifier for X:** A *polynomial time* (thus efficient) algorithm A with output {yes, no}. 
    1. **Input to A:** *(I, s)*, where s is the proposed solution
2. **Behaviour:** A can *verify* if proposed solution *s* is right or wrong

How to capture the fact that *s* is short
1. **Behavior:** There is a polynomial function *p* such that *I* is a yes-instance of *X* **iff** there exists a string *s* with \$ \mid s \mid \leq p(\mid I \mid) \$ such that *A* outputs *yes* on input *(I, s)*.

<!-- Q: What's |S| ≤ p(i)? -->

**Definition.** (NP) The set of all **decision** problems which have an **efficient certifier**.

> NP: non-deterministic polynomial time.

**Definition.** (P) The set of all decision problems which have **efficient** (poly-time) algorithm.

> What is the relation between P and NP?

$$
P \subset NP
$$

Use the efficient poly-time algorithm to decide the outcome of an input instance (thus acting as a certifier); the proposed solution is ignored.

> Note that P = NP is an unresolved ($1m) problem

## NP Complete
A problem *X* in *NP* class is *NP-complete* if for every \$ A \in NP \$

$$
A \leq_P X
$$

![NP Complete](/assets/img/2020-16-1-CS3230/np-complete-diagram.png)

> If *X* is not known to be in NP, then we say X is just NP-hard.

## Satisfiability (CNF-SAT)
1. **Literal:** Boolean variable or its negation
2. **Clause:** A disjunction of literals
3. **CNF:** A formula \$ \phi \$ that is a conjunction of clauses
4. **CNF-SAT:** Given a CNF formula \$ \phi \$, does it have a satisfying truth assignmnet?

**3-SAT:** SAT where each clause contains exactly 3 literals corresponding to the different variables.

$$
\text{Circuit Satisfiability} \leq_P CNF-SAT \leq_P 3-SAT
$$

Since Circuit Satisfiability is NP-complete, all its problems can be reduced to 3-SAT, thus 3-SAT is NP-complete.

> Is P = NP?

![P versus NP](/assets/img/2020-16-1-CS3230/p-versus-np.png)

If any NP-complete problem *X* is solve in polynomial time (ie intersection between NP-complete and P), then any NP problem can be reduced to *X*, which equals P. Only if the condition is satisfied, is P = NP.

## How to show a problem to be NP-complete

![Show NP Complete](/assets/img/2020-16-1-CS3230/show-NP-complete.png)

# Approximation Algorithms
## Approximation Ratio
Let \$ C^* \$ be the optimal cost and *C* be the cost of the solution given by an approximation algorithm A.

An approximation algorithm *A* has an **approximation ratio** of \$ p(n) \$ if:

$$
\frac{C}{C^*} \leq p(n) \text{(for minimisation)} \\
\frac{C}{C^*} \geq p(n) \text{(for maximisation)} \\
$$

> Trick is to find relation between \$ C \$ and \$ C^\* \$. For example in Tutorial 12

$$
\mid V_m \mid = 2 \mid M \mid \leq 2 Opt \\
\frac{V_m}{Opt} \leq 2
$$

Approximation ratio for the minimisation problem is thus 2.

## Two General Approaches
1. **Analyze a heuristic:** A "heuristic" is a procedure that does not always produce the optimal answer. Sometimes, we can show that it's not too bad though.
2. **Solve an LP relaxation:** Many problems can be reduced to Integer Programming. Solve the Linear Programming version instead.

> **Linear Programmin:** Linear Programming (LP) is an attempt to find a maximum or minimum solution to a function, given that contraints have to be linear.

> **Integer Programming:** Integer Programming is a subset of Linear Programming. It has all the characteristics of an LP except for one caveat: the solution to the LP must be restricted to integers.

**Fully Poynomial Time Approximation Scheme:** For any \$ 0 < \epsilon < 1 \$, there is an algorithm that has approx ratio \$ 1 - \epsilon \$ and running time \$ poly(\frac{n}{\epsilon}) \$.