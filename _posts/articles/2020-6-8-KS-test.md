---
layout: post
title: "The Kolmogorov-Smirnov Test"
author: "Larry Law"
categories: articles
tags: [prob-and-stats]
image: prob-stats.png
---
*(IMO, this [set of slides](http://www.stats.ox.ac.uk/~massa/Lecture%2013.pdf) from the University of Oxford explains KS-test in a relatively more rigorous, accurate and updated manner; here's my summary for it.)*

## Learning Outcomes
1. The Kolmogorov-Smirnov Test (KS)
2. The KS Test for two samples

## The Kolmogorov-Smirnov Test (KS)
Suppose that we have observations \$ X_1, \cdots, X_n \$ which we think come from a distribution \$ P \$. The *KS Test* is used to test 
1. \$ H_0 \$: the samples come from \$ P \$ **against**
2. \$ H_1 \$: the samples do not come from \$ P \$.

### Empirical Cumulative Distributive Function (ECDF)
Recall that the *cumulative distribution function* \$ F(x) \$ of a random variable \$ X \$ is 

$$ F(x) = P(X \leq x) $$

Given observations \$ x_1, \cdots, x_n \$, the empirical CDF \$ F_{obs}(x) \$ gives the proportion of the data that lies below \$ x \$ (as opposed to the probability \$ P(X = x) \$).

$$ F_{obs}(x) = \frac{\text{#observations below x}}{\text{#observations}} $$

If we made the observations \$ y_1 \leq y_2 \leq \cdots \leq y_n \$, then 

$$ F_{obs}(y_i) = \frac{i}{n} $$

> ECDF is a step function that increases by \$ 1/N \$ at the value of each ordered data point. 

We want to compare the ECDF, \$ F_{obs} \$, with the CDF associated with the null hypothesis, \$ F_{exp} \$ (expected CDF).

### KS-Statistic

$$ D_n = max_n \lvert F_{exp}(x) - F_{obs}(x) \rvert $$

### Computation Procedure 
If our data is ordered, \$ x_1 \$ being the least and \$ x_n \$ being the largest, then
1. For each observation, compute \$ F_{obs}(x_i) \$ and \$ F_{exp}(x_i) \$. From the ECDF and CDF, compute their absolute difference, \$ \lvert F_{exp}(x) - F_{obs}(x) \rvert $
2. Taking the maximum of the absolute difference, we'll obtain the KS statistic.

Visually, step one computes all the green lines in the plot and step two takes the green line of largest vertical distance.

![KS Test Graph](/assets/img/2020-6-8-KS-test/ks-test.png)

### Critical Value
If KS-statistic \$ D_n \$ is lesser than the critical value \$ D_{crit} \$, we *do not reject* the null hypothesis. At 95% level, the critical value is approximately given by 

$$ D_{crit, 0.05} = \frac{1.36}{n^{0.5}} $$

## KS for Two Samples
Given two samples, test if their distributions are the same.

1. Sort the combined sample
2. Compute the ECDF of the two sample distributions and compute their maximum difference.

Visually, it will look this.

![KS two sample Graph](/assets/img/2020-6-8-KS-test/ks-two-sample.png)

For the two samples, the 95% critical value can be approximated by the formula: 

$$ D_{crit, 0.05} = 1.36 \sqrt{\frac{1}{n_x} + \frac{1}{n_y}} $$

where \$ n_x, n_y \$ denote the size of sample set \$ X, Y \$ respectively.

<!-- > Doesn't this make KS for two samples sensitive to anomalies? -->
