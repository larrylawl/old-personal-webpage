I"M
<div align="center">
    <i>"Only half of programming is coding. The other half is debugging." - Unknown</i>
</div>

<!-- omit in toc -->
<h2 id="learning-outcomes">Learning outcomes</h2>
<ul>
  <li><a href="#purpose-of-learning-curves">Purpose of Learning Curves</a></li>
  <li><a href="#interpreting-learning-curves">Interpreting Learning Curves</a></li>
  <li><a href="#implementation-of-learning-curves-in-matlaboctave">Implementation of Learning Curves in MatLab/Octave</a></li>
</ul>

<h2 id="purpose-of-learning-curves">Purpose of Learning Curves</h2>
<p>Learning curves diagnose <strong>underfitting/high bias</strong> (left graph) and <strong>overfitting/high variance</strong> (right graph) problems.</p>

<blockquote>
  <p>A model that underfits are biased for its assumption despite the training data saying otherwise.</p>
</blockquote>

<blockquote>
  <p>In statistics, variance can be interpreted as how far the data are spread out. A model that overfits make predictions on new data that are very far off the expected value, thus it has high variance.</p>
</blockquote>

<p><img src="/assets/img/fitting.jpg" alt="fitting" /></p>

<h2 id="interpreting-learning-curves">Interpreting Learning Curves</h2>
<p>Learning curve plots the error over the training set size <em>N</em>. More concretely, it is a function of <em>N</em>, that outputs the cost function at <em>N</em>.</p>

<blockquote>
  <p>Example of the MSE cost function to see the influence of <em>N</em> on <em>J</em>.
<script type="math/tex">J(\theta)=\frac{1}{2 N} \sum_{i=1}^{N}\left(\hat{y}_{i}-y_{i}\right)^{2}=\frac{1}{2 N} \sum_{i=1}^{N}\left(h_{\theta}\left(x_{i}\right)-y_{i}\right)^{2}</script></p>
</blockquote>

<p><img src="/assets/img/learning-curve-underfit.png" alt="Learning Curve of High Bias" /></p>

<p>Learning Curve of model with <em>High Bias</em>. In particular,</p>
<ol>
  <li><strong>Training error and test error converges.</strong> Consider the underfitting example above on the left. When <em>N</em> is high, the model is not able to optimise the line much more as it is trying to fit a linear equation to a quadratic/log set of data points. Since the model is not changing much, both the training and test error stagnates.</li>
  <li></li>
</ol>

<p><img src="/assets/img/learning-curve-overfit.png" alt="Learning Curve of High Variance" /></p>

<h2 id="implementation-of-learning-curves-in-matlaboctave">Implementation of Learning Curves in MatLab/Octave</h2>

<!-- omit in toc -->
<h2 id="credits">Credits</h2>
<p>Andrew Ngâ€™s Machine Learning course. Source <a href="https://www.coursera.org/learn/machine-learning">here</a>.</p>
:ET