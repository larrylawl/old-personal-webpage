I"#<div align="center">
    <i>"Only half of programming is coding. The other half is debugging." - Unknown</i>
</div>

<!-- omit in toc -->
<h2 id="learning-outcomes">Learning outcomes</h2>
<ul>
  <li><a href="#prerequisite-geometric-interpretation-of-dot-product">Prerequisite: Geometric Interpretation of Dot Product</a></li>
  <li><a href="#large-margin-intuition">Large Margin Intuition</a></li>
  <li><a href="#math-behind-large-margin">Math Behind Large Margin</a></li>
</ul>

<h2 id="prerequisite-geometric-interpretation-of-dot-product">Prerequisite: Geometric Interpretation of Dot Product</h2>

<p>The dot product is defined for two vectors X and Y by
<script type="math/tex">X \cdot Y = |X||Y|cos\theta</script>
where $ \theta $ is the angle between the vectors and |X| is the length of the vector (or the norm). Consequently, the dot product has the geometric interpretation of the length of projection X on Y, multiplied by the norm of Y (or vice versa, since dot product is commutative).</p>

<h2 id="large-margin-intuition">Large Margin Intuition</h2>

<h2 id="math-behind-large-margin">Math Behind Large Margin</h2>

<p>Minimise cost function –&gt; LHS = 0 –&gt; thetax ≥ 1 –&gt; Sub in –&gt; P must be large –&gt; margin will be far away</p>

<!-- omit in toc -->
<h2 id="credits">Credits</h2>
<p>Mathworld for the interpretation of Dot Product. Source <a href="http://mathworld.wolfram.com/DotProduct.html">here</a>.</p>

<p>Andrew Ng’s Machine Learning course. Source <a href="https://www.coursera.org/learn/machine-learning">here</a>.</p>
:ET