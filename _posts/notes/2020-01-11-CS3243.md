---
layout: post
title: "NUS, CS3243: Introduction to AI"
author: "Larry Law"
categories: notes
image: cs.jpeg
hidden: true
---
Lecturer: Zick Yair <br>

Questions:
1. Model of world?

<!-- omit in toc -->
# Table of Contents
- [Introduction](#introduction)
  - [When Can a Machine Truly Think?](#when-can-a-machine-truly-think)
  - [Rational Agents](#rational-agents)
  - [Specifying Task Environment: PEAS](#specifying-task-environment-peas)
  - [Agenty Types](#agenty-types)
    - [Simple Reflex Agent](#simple-reflex-agent)
    - [Model-based Reflex Agent](#model-based-reflex-agent)
    - [Goal-based agent](#goal-based-agent)
    - [Utility-based agent](#utility-based-agent)
    - [Tradeoff between Exploitation and Exploration](#tradeoff-between-exploitation-and-exploration)

# Introduction
## When Can a Machine Truly Think?

**Turing Test:**  A computer passes the test if a human interrogator, after
posing some *written* questions, cannot tell whether the written responses come from a person or from a computer. 

**Winograd Schema:** 
1. You are given *m* Winograd schema, with the context word chosen uniformly at random.
2. Design an AI that can correctly resolve a significant number of them.

Above examples show that single test for Intelligence is...
1. Difficult to resolve
2. Tests tend to be 1) over-specified or 2) very subjective (tradeoff!)
3. Results will be debatable

## Rational Agents

**Agent:** Function maps *percept histories* to *actions*

**Rational agent:**
1. For each possible percept sequence, select an action that is expected to *maximize its performance measure*
2. given the evidence provided by the percept sequence and whatever built-in knowledge the agent has.

## Specifying Task Environment: PEAS

Task environment is used for intelligent agent design. PEAS stands for
1. Performance measure
2. Environment
3. Actuators
4. Sensors

Properties of Task Environments include
1. **Fully observable (vs. partially observable):** sensors provide access to the complete state of the environment at each point in time.
2. **Deterministic (vs. stochastic):** The next state of the environment is completely determined by the current state and the action executed by the agent
3. **Episodic (vs. sequential):** The choice of current action does not depend on actions in past episodes (or memorylessness)
4. **Static (vs. dynamic):** The environment is unchanged while an agent is
deliberating.
5. **Discrete (vs. continuous):** A finite no. of distinct states, percepts, and actions. (turn based)
6. **Single agent (vs. multi-agent):** An agent operating by itself in an env.

**Peformance measure:** Objective criterion for measuring success of an agent's behaviour.

## Agenty Types
### Simple Reflex Agent
1. Passive: only acts when it observes a percept
2. Updates *state* based on *percept* only.
3. Easy to implement.

### Model-based Reflex Agent
1. Passive: only acts when it observes a percept
2. Updates *state* based on *percept*, current *state*, most recent *action*, and *model of the world*

### Goal-based agent
1. Has **goals**, acts to achieve them (not passive)
2. Updates *state* based on *percept*, current *state*, most recent *action*, and *model of the world*

### Utility-based agent
1. Has **utility function**, acts to achieve them (not passive)
2. Updates *state* based on *percept*, current *state*, most recent *action*, and *model of the world*

### Tradeoff between Exploitation and Exploration
Tradeoff between
1. **Exploitation**: maximizing its expected utility according to its current knowledge of the world
2. **Exploration**: trying to learn more about the world since this may improve its future gains
